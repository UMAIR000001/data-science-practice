{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzLwHhgYtcXcUr9NuRJsa8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UMAIR000001/PyTorch-Week4/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''# 1. Install Git (if needed)\n",
        "!apt-get install git\n",
        "\n",
        "# 2. Set your Git username & email (only once)\n",
        "!git config --global user.email \"umairhafeez951@gmail.com\"\n",
        "!git config --global user.name \"UMAIR000001\"\n",
        "\n",
        "# 3. Clone your GitHub repo to Colab\n",
        "!git clone https://github.com/UMAIR000001/PyTorch-Week4.git'''\n"
      ],
      "metadata": {
        "id": "3yN6d6KGIfgl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "13fa3bf7-1667-4c94-f4b3-a515a4629cf6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# 1. Install Git (if needed)\\n!apt-get install git\\n\\n# 2. Set your Git username & email (only once)\\n!git config --global user.email \"umairhafeez951@gmail.com\"\\n!git config --global user.name \"UMAIR000001\"\\n\\n# 3. Clone your GitHub repo to Colab\\n!git clone https://github.com/UMAIR000001/PyTorch-Week4.git'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PmUe4654eJEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88f6d02-164a-489c-e474-aa840b4a4376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first day of learning Pytorch\n"
          ]
        }
      ],
      "source": [
        "print(\"first day of learning Pytorch\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "-ToV8qareVFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a75cd1-d912-47d8-abed-439b8fd53871"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Introduction To Tensors\n",
        "### Creating Tensors"
      ],
      "metadata": {
        "id": "3AcKlzDUg5Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scalar\n",
        "scalar =torch.tensor(5366)\n",
        "scalar"
      ],
      "metadata": {
        "id": "t1T2eI1PjllB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807919d0-f931-46d9-8648-0779a1cef7f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5366)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of dimensions of vector\n",
        "scalar.ndim"
      ],
      "metadata": {
        "id": "UtD-7NAkjlaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e33a9a-30b6-46d5-a92b-cd6ff665aada"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get tensor back as python int\n",
        "scalar.item()"
      ],
      "metadata": {
        "id": "_bG5XgE4jlKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be70853-402d-480b-c2f0-4b27f3402371"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5366"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vector\n",
        "vector=torch.tensor([1,2,3,4,5])\n",
        "vector"
      ],
      "metadata": {
        "id": "bLO-NXxTk8ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e35ebae-f7f2-4079-ffc3-b3ec35ef1b49"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of dimensions of vector\n",
        "vector.ndim"
      ],
      "metadata": {
        "id": "rmNMLmlUk8FF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53924095-cedc-4a97-a6f8-b1d887216bf8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another important concept for tensors is their shape attribute. The shape tells you how the elements inside them are arranged.\n",
        "vector.shape"
      ],
      "metadata": {
        "id": "Fsr3tkMAk8Bq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972481df-6592-46a7-8c06-ae558e14101e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MATRIX\n",
        "MATRIX=torch.tensor([[1,2],[3,4]])\n",
        "MATRIX"
      ],
      "metadata": {
        "id": "feLbdZbEk73n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b72694a-1c6d-41c0-8327-5735a19adb6a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.ndim"
      ],
      "metadata": {
        "id": "xoSyZlfsmJH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81cbb0d6-9c22-474a-b4b8-bc05853fd675"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX[0]"
      ],
      "metadata": {
        "id": "B6QYOv52mJEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60127bec-d0be-44cf-a7d8-7bb628349008"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.shape"
      ],
      "metadata": {
        "id": "q6ajlyrvmI-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6a2aa9-a152-4ea1-8e89-75fbd4c7907c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TENSOR\n",
        "TENSOR=torch.tensor([[[1,1,1],[2,2,2]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "id": "6YZP2hlHmI1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979f676e-d079-4cf3-d968-ab036487a94a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 1, 1],\n",
              "         [2, 2, 2]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.ndim"
      ],
      "metadata": {
        "id": "NBQUC74vmhfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9c03f4-0600-49c7-ffe1-060e16d0eb6c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "id": "9vtC4meQ0QKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac727d93-f3d5-4b02-dc67-9fce165d73a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Randon tensors\n",
        "A random tensor is a multi-dimensional array filled with randomly generated values, created using PyTorch functions like torch.rand(), torch.randn(), or torch.randint().\n",
        "\n",
        "->These tensors are often used to:\n",
        "\n",
        "->Simulate input data\n",
        "\n",
        "->Initialize weights of neural networks\n",
        "\n",
        "->Test models before using real data\n",
        "\n",
        "##Different Random Tensor Functions\n",
        "\n",
        "1:\n",
        "Function    |\tRange of Values             |Data Type\n",
        "torch.rand()|\tUniform random values [0, 1)|float32\n",
        "\n",
        "\n",
        "##❓Why are random tensors so valuable in deep learning?\n",
        "In deep learning, we start with random numbers (random tensors) to initialize model parameters (like weights).\n",
        "Then the model:\n",
        "\n",
        "🔁 Looks at data → compares predictions to real values\n",
        "\n",
        "🔁 Updates the random numbers (weights) using gradients\n",
        "\n",
        "🔁 Repeats this process until the model learns to make accurate predictions.\n",
        "\n",
        "\n",
        "## 💡 Why Use Random Tensors Instead of Zero?\n",
        "If all weights were zero, the model would learn nothing unique (all neurons behave the same).\n",
        "Randomness breaks symmetry, allowing each neuron to learn something different."
      ],
      "metadata": {
        "id": "pAmdxCxV1Bl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hCJZO2CMfYd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Create a random tensor of size (5,2)\n",
        "#random_tensor=torch.rand(size=(5,3)) == random_tensor=torch.rand(5,3)\n",
        "random_tensor=torch.rand(size=(5,3))\n",
        "random_tensor,random_tensor.dtype\n"
      ],
      "metadata": {
        "id": "lALPGgxR1IyB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff78999-cd61-42be-d0ed-57e35f1d2103"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5873, 0.0168, 0.3431],\n",
              "         [0.5904, 0.0139, 0.7424],\n",
              "         [0.7195, 0.5266, 0.2479],\n",
              "         [0.2164, 0.6405, 0.4335],\n",
              "         [0.2704, 0.7759, 0.5017]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The flexibility of `torch.rand()` is that we can adjust the `size` to be whatever we want.\n",
        "\n",
        "For example, say you wanted a random tensor in the common image shape of `[224, 224, 3]` (`[height, width, color_channels`]).\n",
        "##🧠 Key Point to Remember:\n",
        "In image processing:\n",
        "\n",
        "A color image is usually a 3D tensor → height × width × channels\n",
        "\n",
        "A batch of images becomes a 4D tensor → batch_size × height × width × channels"
      ],
      "metadata": {
        "id": "wHRVAvrfmWR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (224, 224, 3)\n",
        "random_image_size_tensor = torch.rand(224, 224, 3)\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "id": "yAJnRHgUhvx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "888a5357-ee0b-44b7-fdb4-ed5c6f5d0621"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of all task of  random tensor\n",
        "demo_tensor=torch.rand(size=(2,5))\n",
        "demo_tensor,demo_tensor.dtype, demo_tensor.shape,demo_tensor.ndim"
      ],
      "metadata": {
        "id": "hPYEJpv7n_Ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db31fc48-b5d5-400a-c00f-ab003531bc51"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.9352, 0.0806, 0.4038, 0.9673, 0.6434],\n",
              "         [0.9594, 0.3085, 0.1899, 0.0648, 0.1386]]),\n",
              " torch.float32,\n",
              " torch.Size([2, 5]),\n",
              " 2)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zeros and Ones"
      ],
      "metadata": {
        "id": "LPnxbRv4pX9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a tensor all of zeros\n",
        "# probably used in most cases\n",
        "zeros_tensor=torch.zeros(2,5)\n",
        "#Multiplication of Zeros tensor to a random tensor\n",
        "zeros_tensor*demo_tensor\n",
        "#zeros_tensor,zeros_tensor.dtype,zeros_tensor.shape,zeros_tensor.ndim"
      ],
      "metadata": {
        "id": "eMQ9FX27o66z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4143db2e-f969-481e-acd0-730fc6b0996f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a tensor all of ones\n",
        "ones_tensor=torch.ones(2,5)\n",
        "#Multiplication of Ones tensor to a random tensor\n",
        "ones_tensor*demo_tensor\n",
        "#ones_tensor,zeros_tensor.dtype,zeros_tensor.shape,zeros_tensor.ndim"
      ],
      "metadata": {
        "id": "RUx30AN3qfth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7acc08-bd54-47a2-a7ff-5c20b348304f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9352, 0.0806, 0.4038, 0.9673, 0.6434],\n",
              "        [0.9594, 0.3085, 0.1899, 0.0648, 0.1386]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16. Creating a range of tensors and tensors-like"
      ],
      "metadata": {
        "id": "zGjfH5Atr-Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.arange()\n",
        "one_to_ten=torch.arange(start=1,end=11,step=1)\n",
        "one_to_ten\n"
      ],
      "metadata": {
        "id": "ZlLWCcL5sVO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d7f1e5-ce80-481a-ccba-c876d569fed9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_to_twenties=torch.arange(start=0,end=21,step=2)\n",
        "zero_to_twenties"
      ],
      "metadata": {
        "id": "zDwU7YQgtZ4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ba4f04-3ca5-460b-fc47-2b85413e6523"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating tensors like for ones\n",
        "one_to_ten_like=torch.ones_like(input=one_to_ten)\n",
        "one_to_ten_like\n"
      ],
      "metadata": {
        "id": "O5SA93zIuXDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23160290-692c-4648-f841-9b949d270de3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating tensors like for zeros\n",
        "one_to_ten_like=torch.zeros_like(input=one_to_ten)\n",
        "one_to_ten_like\n"
      ],
      "metadata": {
        "id": "K1TUkKuwu5r2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2619609c-6074-489a-df9d-a98e138551fb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensors like for random tensors here typecasting is required\n",
        "demo=torch.rand_like(input=one_to_ten,dtype=torch.float32)\n",
        "demo"
      ],
      "metadata": {
        "id": "EOdbQ_XuwMWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94906141-f484-48b1-80c9-4a2c5c3c8e69"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0481, 0.7514, 0.8569, 0.4025, 0.1986, 0.4329, 0.3331, 0.7121, 0.8388,\n",
              "        0.1469])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 17 Dealing With tensor datatypes"
      ],
      "metadata": {
        "id": "o7NClE9sxkFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default Datatype for tensors is float32 for float values\n",
        "\n",
        "float_32_tensor=torch.tensor((1.0,2.0,3.0),\n",
        "                              dtype=None,\n",
        "                              device=None,\n",
        "                              requires_grad=False)\n",
        "float_32_tensor.dtype,float_32_tensor.device,float_32_tensor.requires_grad,float_32_tensor.shape,float_32_tensor.ndim,float_32_tensor"
      ],
      "metadata": {
        "id": "b8Go3Hm-zKoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b34adcdd-e8e9-464a-e07c-20a125b6bc2b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32,\n",
              " device(type='cpu'),\n",
              " False,\n",
              " torch.Size([3]),\n",
              " 1,\n",
              " tensor([1., 2., 3.]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor=torch.tensor([1,2],\n",
        "                             dtype=torch.float32,\n",
        "                             device=None,\n",
        "                             requires_grad=False)\n",
        "float_32_tensor.dtype"
      ],
      "metadata": {
        "id": "8-rRTZ0ix39x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e308793f-9e86-4e02-85d0-4e948c60a571"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Information for Tensors"
      ],
      "metadata": {
        "id": "nVi8NVni9cxm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fmAKwQ-l9dZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Manipulating tensors (tensor operations)\n"
      ],
      "metadata": {
        "id": "j98cVRlk9V5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic operations\n"
      ],
      "metadata": {
        "id": "i-Xd5TgWG3cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a=torch.tensor([1,2,3])\n",
        "b=torch.tensor([4,5,6])\n",
        "\n",
        "print(\"Addition Of tensors: \",a+b)\n",
        "print(\"Subtraction Of tensors: \",a-b)\n",
        "print(\"Multiplication Of tensors: \",a*b)\n",
        "print(\"Division Of tensors: \",a/b)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFjAbW9j9i7D",
        "outputId": "19d9633f-1f39-4236-be8c-c9ca0fde3e69"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition Of tensors:  tensor([5, 7, 9])\n",
            "Subtraction Of tensors:  tensor([-3, -3, -3])\n",
            "Multiplication Of tensors:  tensor([ 4, 10, 18])\n",
            "Division Of tensors:  tensor([0.2500, 0.4000, 0.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication:\n",
        "This is super important in deep learning — it’s how layers connect to each other.\n",
        "* In Doing Matrix Multiplication between two  matrices we commonly faced  Shape mismatch erorr therefore for that we use transpose to eliminate that error.\n"
      ],
      "metadata": {
        "id": "U83OKEPH-syh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([[1, 2, 3], [1, 2, 3]])  # (2, 3)\n",
        "y = torch.tensor([[4, 5, 6], [4, 5, 6]])  # (2, 3)\n",
        "\n",
        "y = y.T  # Transpose y → (3, 2)\n",
        "\n",
        "result = torch.matmul(x,y)\n",
        "\n",
        "print(\"The Matrix Multiplication of x and y is:\\n\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPob6L85-45a",
        "outputId": "989993f5-8303-4b3a-ce8f-887751cf80aa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Matrix Multiplication of x and y is:\n",
            " tensor([[32, 32],\n",
            "        [32, 32]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transpose of Matrix:\n",
        "##📌 Main Points:\n",
        "In deep learning, models learn using matrix operations (like torch.matmul()).\n",
        "\n",
        ">For matrix multiplication, the number of columns in the first tensor must match the number of rows in the second.\n",
        "\n",
        ">Transpose adjusts tensor shapes so matrix multiplication becomes possible.\n",
        "\n",
        ">Used often when:\n",
        "\n",
        "> >Connecting layers in a neural network\n",
        "\n",
        ">>Multiplying weight matrices and input tensors\n",
        "\n",
        ">>Preprocessing input data"
      ],
      "metadata": {
        "id": "x0b7PoYlHSW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x =torch.tensor([[1,2,3],[4,5,6]])\n",
        "\n",
        "print(f\"The shape of matix x is {x.shape}\")\n",
        "\n",
        "x=x.T # Taking Transpose\n",
        "\n",
        "print(f\"The shape of matix x after transpose is {x.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFLOas7oHR3t",
        "outputId": "913792dc-1780-4eaa-e21f-e46e74bcbc1d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of matix x is torch.Size([2, 3])\n",
            "The shape of matix x after transpose is torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding the min, max, mean, sum, etc (aggregation)"
      ],
      "metadata": {
        "id": "mlTLzdGvJvLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor = torch.tensor([1,2,3,4,5,6])\n",
        "\n",
        "print(\"Tensor:\\n\", tensor)\n",
        "\n",
        "# Aggregation operations\n",
        "print(\"\\nMin:\",tensor.min())\n",
        "print(\"Max:\", tensor.max())\n",
        "print(\"Sum:\", tensor.sum())\n",
        "print(\"Mean:\", tensor.type(torch.float32).mean())  # mean needs float type\n",
        "print(\"Product:\",tensor.prod())\n",
        "print(\"Standard Deviation:\", tensor.type(torch.float32).std())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co9oy9D2JuvU",
        "outputId": "007b3254-3cb2-41aa-d463-fc3a4c1d737a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:\n",
            " tensor([1, 2, 3, 4, 5, 6])\n",
            "\n",
            "Min: tensor(1)\n",
            "Max: tensor(6)\n",
            "Sum: tensor(21)\n",
            "Mean: tensor(3.5000)\n",
            "Product: tensor(720)\n",
            "Standard Deviation: tensor(1.8708)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Positional min/max\n",
        "argmax and argmin are used to show the index number of maximum number as well as for Minimum number"
      ],
      "metadata": {
        "id": "ZAmvL0RGNDpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo_tensor=torch.arange(start=0,end=21,step=2)\n",
        "\n",
        "print(f\"The tensor elements are : {demo_tensor}\")\n",
        "\n",
        "print(f\"THe Index of Maximum element in our tensor is {torch.argmax(demo_tensor)}\")\n",
        "\n",
        "print(f\"THe Index of Maximum element in our tensor is {torch.argmin(demo_tensor)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbDVegncKiQx",
        "outputId": "313bea1e-969c-44d1-e5db-fbc943a02215"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensor elements are : tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20])\n",
            "THe Index of Maximum element in our tensor is 10\n",
            "THe Index of Maximum element in our tensor is 0\n",
            "tensor(20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Change tensor datatype:\n",
        "A common issue with deep learning operations is having your tensors in different datatypes.\n",
        "so practicing changing the data type of a tensor"
      ],
      "metadata": {
        "id": "cSpKxnEaOSAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 Step 1: Initialize a tensor from 0 to 9\n",
        "tensor_A = torch.arange(start=0, end=10, step=1)\n",
        "\n",
        "# 🔹 Step 2: Check its original data type\n",
        "print(f\"The tensor is {tensor_A} with the original datatype: {tensor_A.dtype}\")\n",
        "\n",
        "# 🔹 Step 3: Change its data type explicitly to float32\n",
        "tensor_A = tensor_A.type(torch.float32)\n",
        "\n",
        "# 🔹 Step 4: Print the updated tensor and its new data type\n",
        "print(f\"The tensor is {tensor_A} with the updated datatype: {tensor_A.dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0e6wvK0ORtp",
        "outputId": "7d887672-5af9-4c41-cf94-672adcc085fa"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensor is tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) with the original datatype: torch.int64\n",
            "The tensor is tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]) with the updated datatype: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reshaping, stacking, squeezing and unsqueezing:\n",
        "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
        " >These 4 concepts — reshaping, stacking, squeezing, and unsqueezing — are very important in PyTorch for organizing tensor shapes before feeding them into a neural network"
      ],
      "metadata": {
        "id": "kOPSVcfjbFum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reshaping\n",
        "You can reshape into any size as long as:\n",
        "\n",
        "product of dimensions\n",
        "=\n",
        "total number of elements\n",
        "product of dimensions=total number of elements\n",
        "in the below example number of elements are 9 and product of dimension is also 9 (3*3)"
      ],
      "metadata": {
        "id": "Z5nQl2JhgJW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(9)\n",
        "\n",
        "print(f\"The tensor is {x} and its shape is {x.shape}\")\n",
        "\n",
        "\n",
        "#Reshaping\n",
        "reshape_x=x.reshape(3,3)\n",
        "\n",
        "print(f\"\\nThe tensor is {x} and its shape is {reshape_x.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voR6pxYNXZWA",
        "outputId": "8fa3552d-6b39-4d47-e8b3-d5e994517118"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensor is tensor([0, 1, 2, 3, 4, 5, 6, 7, 8]) and its shape is torch.Size([9])\n",
            "\n",
            "The tensor is tensor([0, 1, 2, 3, 4, 5, 6, 7, 8]) and its shape is torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You can add an Extra Dimension in a tensor"
      ],
      "metadata": {
        "id": "aCv0Oygq5H76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(8)\n",
        "\n",
        "print(f\"The tensor is {x} and its shape is {x.shape } and the number of Dimension is {x.ndim}\")\n",
        "\n",
        "\n",
        "#Adding an extra Dimension\n",
        "\n",
        "reshape_x=x.reshape(1,8)\n",
        "\n",
        "print(f\"The tensor is {x} and its shape is {x.shape } and the number of Dimension is {x.ndim}\")"
      ],
      "metadata": {
        "id": "wg34cK1Fg48k"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# torch.view\n",
        "\n",
        "We can also change the view with torch.view().\n",
        ">Remember though, changing the view of a tensor with torch.view() really only creates a new view of the same tensor.\n",
        "\n",
        "So changing the view changes the original tensor too."
      ],
      "metadata": {
        "id": "CBAoBeTJ7QWu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kvkttC1X7S23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#torch.stack():\n",
        "\n",
        ">If we wanted to stack our new tensor on top of itself five times, we could do so with torch.stack()."
      ],
      "metadata": {
        "id": "RvJxgvdE8twO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(1,6)\n",
        "print(f\"Original Tensor is {x}\")\n",
        "\n",
        "print(\"stacking horizontally:\")\n",
        "torch.stack([x,x,x],dim=0)"
      ],
      "metadata": {
        "id": "JvEKYGJF8w4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(1,6)\n",
        "print(f\"Original Tensor is {x}\")\n",
        "\n",
        "print(\"stacking vertically:\")\n",
        "torch.stack([x,x,x],dim=1)"
      ],
      "metadata": {
        "id": "0GIaznj__tzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#torch.squeeze():\n",
        "\n",
        ">To do so you can use torch.squeeze() (I remember this as squeezing the tensor to only have dimensions over 1).\n",
        "\n",
        "## torch.unsqueeze():\n",
        "> And to do the reverse of torch.squeeze() you can use torch.unsqueeze() to add a dimension value of 1 at a specific index.\n",
        "How about removing all single dimensions from a tensor?"
      ],
      "metadata": {
        "id": "nz7gvjeF_69N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(6)\n",
        "print(f\"The original tensor is {x} having shape {x.shape}\")\n",
        "\n",
        "# Reshpaing the original tenosr\n",
        "print(\"\\nUsing reshape funtion to add an extra dimension\")\n",
        "reshape_x=x.reshape(1,6)\n",
        "print(f\"The Reshape of x  tensor is {reshape_x} having the shape {reshape_x.shape}\")\n",
        "\n",
        "#squeezing\n",
        "print(\"\\nPerofrming Squeezing Function\")\n",
        "new=torch.squeeze(reshape_x)\n",
        "print(f\"the tensor {new} and having the new shape  {new.shape}\")\n",
        "\n",
        "#unsqueezing\n",
        "print(\"\\nPerofrming UnSqueezing Function\")\n",
        "new=new.unsqueeze(dim=0)\n",
        "print(f\"the tensor {new} and having the new shape  {new.shape}\")\n"
      ],
      "metadata": {
        "id": "9yHcZWfBADOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#torch.permute(input, dims):\n",
        "permute() is used to reorder dimensions (useful in images: [C, H, W] → [H, W, C])\n",
        ">You can also rearrange the order of axes values with torch.permute(input, dims), where the input gets turned into a view with new dims.\n",
        "\n",
        ">Note: Because permuting returns a view (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original.\n",
        "> Remember ! 🔹 permute() is used only on multi-dimensional tensors, like 2D, 3D, etc.\n"
      ],
      "metadata": {
        "id": "4lvA1vtCExS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ],
      "metadata": {
        "id": "3C0CjlL8SQ4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#permute is also like tanspose\n",
        "x = torch.rand(2, 3)\n",
        "print(x)\n",
        "# shape is (rows=2, cols=3)\n",
        "print(x.permute(1, 0))\n"
      ],
      "metadata": {
        "id": "h2LZYUbpAjnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Indexing (selecting data from tensors):\n",
        ">Sometimes you'll want to select specific data from tensors (for example, only the first column or second row).\n",
        "\n",
        ">To do so, you can use indexing.\n",
        "\n",
        "If you've ever done indexing on Python lists or NumPy arrays, indexing in PyTorch with tensors is very similar."
      ],
      "metadata": {
        "id": "mt7OyPe2OSsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1D Tensor (like array):"
      ],
      "metadata": {
        "id": "Uzd-96X6UxKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([10, 20, 30, 40])\n",
        "print(x[0])  # 👉 10 (first element)\n",
        "print(x[2])  # 👉 30 (third element)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6iL_xpaUveR",
        "outputId": "c06963a9-16d4-44a7-81ff-93e61a27b92c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10)\n",
            "tensor(30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2D Tensor (matrix):\n",
        "Let’s take this matrix (2 rows, 3 columns):"
      ],
      "metadata": {
        "id": "HVvhB0wyVnqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n"
      ],
      "metadata": {
        "id": "OxJwwi6yVtgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ Select first row\n",
        "print(\"x[0] =\", x[0])         # 👉 tensor([11, 12, 13])\n",
        "\n",
        "# 2️⃣ Select second row, third column\n",
        "print(\"x[1][2] =\", x[1][2])   # 👉 23\n",
        "\n",
        "# 3️⃣ Select all rows, column 0\n",
        "print(\"x[:, 0] =\", x[:, 0])   # 👉 tensor([11, 21, 31])\n",
        "\n",
        "# 4️⃣ Select row 2, all columns\n",
        "print(\"x[2, :] =\", x[2, :])   # 👉 tensor([31, 32, 33])\n",
        "\n",
        "# 5️⃣ Select element at row 0, column 1\n",
        "print(\"x[0, 1] =\", x[0, 1])   # 👉 12\n"
      ],
      "metadata": {
        "id": "WLuJ9vI0WLMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing in a 3D Tensor"
      ],
      "metadata": {
        "id": "CpoDnmHMWPAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 🧠 Creating a 3D Tensor (2 blocks, each with 2 rows and 3 columns)\n",
        "x3 = torch.tensor([\n",
        "    [   # 🔲 Block 0\n",
        "        [1, 2, 3],   # Row 0 of Block 0\n",
        "        [4, 5, 6]    # Row 1 of Block 0\n",
        "    ],\n",
        "    [   # 🔲 Block 1\n",
        "        [7, 8, 9],    # Row 0 of Block 1\n",
        "        [10, 11, 12]  # Row 1 of Block 1\n",
        "    ]\n",
        "])\n",
        "\n",
        "# 🔎 Tensor structure:\n",
        "# Block 0 --> [[1, 2, 3], [4, 5, 6]]\n",
        "# Block 1 --> [[7, 8, 9], [10, 11, 12]]\n",
        "\n",
        "# ✅ Shape of the 3D tensor\n",
        "print(\"Shape of x3:\", x3.shape)  # 👉 torch.Size([2, 2, 3])\n",
        "# Meaning:\n",
        "# 2 blocks (depth), each block has 2 rows, and each row has 3 columns\n",
        "\n",
        "# 📌 Indexing examples for clarity:\n",
        "\n",
        "# Get Block 0 (first 2D matrix)\n",
        "print(\"x3[0] →\\n\", x3[0])  # 👉 [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "# Get Row 0 from Block 1\n",
        "print(\"x3[1][0] →\", x3[1][0])  # 👉 [7, 8, 9]\n",
        "\n",
        "# Get specific element: Block 1 → Row 1 → Column 2\n",
        "print(\"x3[1][1][2] →\", x3[1][1][2])  # 👉 12\n"
      ],
      "metadata": {
        "id": "yLlDEfI9YAJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summary of 3D tenosr:\n",
        "🧠 Summary (copy into notes):\n",
        "x3.shape = [2, 2, 3]\n",
        "→ 2 blocks\n",
        "→ Each block has 2 rows\n",
        "→ Each row has 3 columns\n",
        "\n",
        "x3[0] → Block 0\n",
        "\n",
        "x3[1][0] → Block 1, Row 0\n",
        "\n",
        "x3[1][1][2] → Block 1, Row 1, Column 2 → 12"
      ],
      "metadata": {
        "id": "zE4fwMY0Y3CC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch tensors & NumPy\n",
        "##🔄 Think of it like this:\n",
        "NumPy is a very popular library used in data science and machine learning.\n",
        "\n",
        "PyTorch is built to work easily with NumPy — because both are used to work with numerical data.\n",
        "\n",
        ">So, PyTorch lets you:\n",
        "\n",
        "Convert NumPy array → PyTorch tensor\n",
        "\n",
        "Convert PyTorch tensor → NumPy array\n",
        "\n",
        "This helps you move data back and forth depending on what you're working on."
      ],
      "metadata": {
        "id": "C5XFMb26ZHRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔁 NumPy ↔️ PyTorch Conversion\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# NumPy array → PyTorch tensor\n",
        "np_array = np.array([10, 20, 30])\n",
        "torch_tensor = torch.from_numpy(np_array)\n",
        "\n",
        "print(\"Torch Tensor:\", torch_tensor)  # 👉 tensor([10, 20, 30])\n",
        "\n",
        "# PyTorch tensor → NumPy array\n",
        "back_to_numpy = torch_tensor.numpy()\n",
        "\n",
        "print(\"NumPy Array:\", back_to_numpy)  # 👉 [10 20 30]\n",
        "\n",
        "# 🧠 Notes:\n",
        "# - torch.from_numpy() = NumPy → PyTorch\n",
        "# - tensor.numpy() = PyTorch → NumPy\n",
        "# - Both share the same memory (changing one will affect the other)\n"
      ],
      "metadata": {
        "id": "b5c8blFdY6YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reproducibility (trying to take the random out of random):\n"
      ],
      "metadata": {
        "id": "Esix0ewkqVcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔁 Reproducibility in PyTorch\n",
        "# ----------------------------------\n",
        "\n",
        "import torch\n",
        "\n",
        "# 1️⃣ Random tensors (without seed)\n",
        "random_tensor_1 = torch.rand(3, 4)\n",
        "random_tensor_2 = torch.rand(3, 4)\n",
        "\n",
        "print(\"Without seed → Are they same?\")\n",
        "print(random_tensor_1 == random_tensor_2)  # 👉 False\n",
        "\n",
        "# 2️⃣ Random tensors (with same seed)\n",
        "torch.manual_seed(42)  # Set seed once\n",
        "tensor_c = torch.rand(3, 4)\n",
        "\n",
        "torch.manual_seed(42)  # Set the same seed again before creating a new random tensor\n",
        "tensor_d = torch.rand(3, 4)\n",
        "\n",
        "print(\"With seed → Are they same?\")\n",
        "print(tensor_c == tensor_d)  # 👉 True\n",
        "\n",
        "# 🧠 Summary Notes:\n",
        "# - torch.manual_seed(seed) sets the \"starting point\" for randomness\n",
        "# - Use the same seed to get the same \"random\" numbers every time\n",
        "# - Important for repeatable results in experiments\n",
        "\n",
        "# 🎯 Rule: If your code uses randomness (like torch.rand), always set a seed when testing or debugging\n"
      ],
      "metadata": {
        "id": "SBzk2vC2qSrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running tensors on GPUs (and making faster computations):"
      ],
      "metadata": {
        "id": "uZyaWrabtLx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "WSXSVN54r6Tf",
        "outputId": "83759dfd-a7f6-4fb7-de78-8e99f301c0e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "Vdjeydi7sLTA",
        "outputId": "1ade5c21-bf30-47bb-da88-82a55c756fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "ROkHtLQ8sLPU",
        "outputId": "ecc0aed1-f148-4c63-af65-26eca854f914",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "id": "uaGNZr5dsLM3",
        "outputId": "a9e8d294-dff6-4785-c123-efc17521435c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alhumdulliallah  Completed !"
      ],
      "metadata": {
        "id": "UrTJV2LStTCk"
      }
    }
  ]
}