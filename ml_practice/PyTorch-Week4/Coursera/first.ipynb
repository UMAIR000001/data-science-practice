{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041c9b8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Step 1: Data\n",
    "X = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0]])  # hours studied\n",
    "y = torch.tensor([[0.0], [0.0], [0.0], [1.0], [1.0]])  # passed (0 or 1)\n",
    "\n",
    "# Step 2: Logistic Regression Model (1 input â†’ 1 output)\n",
    "class LogisticModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # simple line: y = wx + b\n",
    "        self.sigmoid = nn.Sigmoid()   # convert output to probability (0 to 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))  # prediction between 0 and 1\n",
    "\n",
    "model = LogisticModel()\n",
    "\n",
    "# Step 3: Loss Function (Binary Cross Entropy)\n",
    "loss_fn = nn.BCELoss()  # because our output is 0 or 1\n",
    "\n",
    "# Step 4: Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  # update weights\n",
    "\n",
    "# Step 5: Training Loop\n",
    "for epoch in range(1000):\n",
    "    # Forward pass (make prediction)\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print every 100 steps\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8361f130",
   "metadata": {},
   "source": [
    "#ðŸ§¾ Whatâ€™s happening here:\n",
    "Model predicts a value between 0 and 1 (probability of passing)\n",
    "\n",
    "Cross-entropy compares this predicted probability with the actual label (0 or 1)\n",
    "\n",
    "If the model is confidently wrong (like predicts 0.9 when actual is 0), it gets a big loss.\n",
    "\n",
    "The optimizer uses this loss to fix the model's weights and improve future predictions.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
